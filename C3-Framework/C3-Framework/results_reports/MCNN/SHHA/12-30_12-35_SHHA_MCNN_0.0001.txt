import os
from easydict import EasyDict as edict
import time
import torch

# init
__C = edict()
cfg = __C

#------------------------------TRAIN------------------------
__C.SEED = 3035 # random seed,  for reporduction
__C.DATASET = 'SHHA' # dataset selection: GCC, SHHA, SHHB, UCF50, QNRF, WE

if __C.DATASET == 'UCF50':# only for UCF50
	from datasets.UCF50.setting import cfg_data
	__C.VAL_INDEX = cfg_data.VAL_INDEX 

if __C.DATASET == 'GCC':# only for GCC
	from datasets.GCC.setting import cfg_data
	__C.VAL_MODE = cfg_data.VAL_MODE 


__C.NET = 'MCNN' # net selection: MCNN, VGG, VGG_DECODER, Res50, CSRNet

__C.PRE_GCC = False # use the pretrained model on GCC dataset
__C.PRE_GCC_MODEL = '' # path to model

__C.GPU_ID = [0] # sigle gpu: [0], [1] ...; multi gpus: [0,1]

# learning rate settings
__C.LR = 1e-4 # learning rate
__C.LR_DECAY = 1 # decay rate
__C.LR_DECAY_START = -1 # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1 # decay frequency
__C.MAX_EPOCH = 3000

# print 
__C.PRINT_FREQ = 30

now = time.strftime("%m-%d_%H-%M", time.localtime())

__C.EXP_NAME = now \
			 + '_' + __C.DATASET \
             + '_' + __C.NET \
             + '_' + str(__C.LR)

if __C.DATASET == 'UCF50':
	__C.EXP_NAME += '_' + str(__C.VAL_INDEX)	

if __C.DATASET == 'GCC':
	__C.EXP_NAME += '_' + __C.VAL_MODE	

__C.EXP_PATH = './exp' # the path of logs, checkpoints, and current codes


#------------------------------VAL------------------------
__C.VAL_DENSE_START = 200
__C.VAL_FREQ = 10 # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ

#------------------------------VIS------------------------
__C.VISIBLE_NUM_IMGS = 1 #  must be 1 for training images with the different sizes



#================================================================================
#================================================================================
#================================================================================  



===============+++++++++++++++===============

all_ep_1_mae_681.1_mse_816.0
    [mae 681.15 mse 815.96], [val loss 0.0962]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_236.6_mse_319.6
    [mae 236.64 mse 319.58], [val loss 0.0761]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_232.3_mse_317.9
    [mae 232.32 mse 317.92], [val loss 0.0750]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_41_mae_182.8_mse_258.3
    [mae 182.77 mse 258.28], [val loss 0.0735]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_51_mae_182.0_mse_244.8
    [mae 181.97 mse 244.76], [val loss 0.0715]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_71_mae_163.7_mse_228.9
    [mae 163.73 mse 228.87], [val loss 0.0703]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_91_mae_156.1_mse_218.0
    [mae 156.09 mse 217.95], [val loss 0.0679]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_161_mae_129.1_mse_188.5
    [mae 129.10 mse 188.46], [val loss 0.0617]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_207_mae_125.1_mse_187.4
    [mae 125.05 mse 187.38], [val loss 0.0605]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_212_mae_126.7_mse_186.0
    [mae 126.67 mse 185.95], [val loss 0.0599]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_215_mae_128.7_mse_185.7
    [mae 128.66 mse 185.71], [val loss 0.0598]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_216_mae_122.3_mse_187.3
    [mae 122.26 mse 187.29], [val loss 0.0607]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_228_mae_120.8_mse_184.1
    [mae 120.83 mse 184.09], [val loss 0.0602]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_265_mae_123.3_mse_182.4
    [mae 123.31 mse 182.36], [val loss 0.0597]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_270_mae_115.9_mse_176.5
    [mae 115.91 mse 176.55], [val loss 0.0591]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_277_mae_115.6_mse_178.9
    [mae 115.57 mse 178.92], [val loss 0.0591]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_298_mae_115.5_mse_176.6
    [mae 115.52 mse 176.55], [val loss 0.0588]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_314_mae_113.2_mse_171.9
    [mae 113.18 mse 171.94], [val loss 0.0580]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_334_mae_110.6_mse_171.1
    [mae 110.64 mse 171.09], [val loss 0.0585]
===============+++++++++++++++===============

